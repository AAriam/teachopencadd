{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T022 - Ligand-based screening: Neural networks\n",
    "\n",
    "Developed in the CADD seminar 2020, Volkamer Lab, Charité/FU Berlin \n",
    "\n",
    "Authors : \n",
    "- Ahmed Atta, CADD Seminar 2020, Charité/FU Berlin\n",
    "- Sakshi Misra, [Volkamer lab](https://volkamerlab.org), Charité\n",
    "- Talia B. Kimber, [Volkamer lab](https://volkamerlab.org), Charité\n",
    "- Prof. Dr. Andrea Volkamer, [Volkamer lab](https://volkamerlab.org), Charité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "In recent years, use of neural networks in pharmaceutical research has shown promise in addressing diverse problems in drug discovery. In this talktorial, we will get familiar with the basic structure of the artificial neural network. Furthermore, we will learn how to build a simple two layer neural network model and use it to predict the pIC50 values of unknown compounds against our target of interest (EGFR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Theory*\n",
    "\n",
    "- Biological background\n",
    "    - EGFR\n",
    "    - Compound activity measures\n",
    "    - Molecule encoding\n",
    "- What is a neural network ?\n",
    "- Basic structure of a neural network\n",
    "- What does a neuron do?\n",
    "- Activation functions\n",
    "- Loss function\n",
    "- Main algorithms in a neural network\n",
    "- Types of neural network\n",
    "- Advantages and applications of neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Practical*\n",
    "\n",
    "- Load data and visualize the dataframe\n",
    "- Data preparation: molecule encoding\n",
    "- Define keras model\n",
    "- Choose the most appropriate batch sizes\n",
    "- Fit keras model\n",
    "- Evaluate keras model\n",
    "- Prediction on test data\n",
    "- Model evaluation on test data\n",
    "- Plotting to compare the distribution of pIC50 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EGFR\n",
    "\n",
    "- [Epidermal growth factor receptor (EGFR)](https://de.wikipedia.org/wiki/EGF-Rezeptor) is a transmembrane protein/receptor present on the cell membrane. It is a member of the ErbB family of receptors. They have an extracellular binding  component/domain, a hydrphobic transmembrane component/domain and an intracelluar tyrosine kinase component/domain. \n",
    "\n",
    "- EGFRs play an important role in controlling normal cell growth, apoptosis and other cellular functions. \n",
    "\n",
    "- It is activated by binding of its specific ligands, upon activation by its growth factor ligands EGFR undergoes a transition from an inactive monomeric form to an active homodimers.\n",
    "\n",
    "- The EGFR receptor is upregulated in various types of tumors or cancers, so an EGFR inhibition is a type of biological therapy that might stop cancer cell from growing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compound activity measures\n",
    "\n",
    "**IC50** is the half maximal inhibitory concentration of the drug which indicates how much a drug is needed to inhibit a biological process by half and in our case the epidermal growth factor receptor as its inhibition helps in slow down or stop cancer cell growth. \n",
    "\n",
    "**pIC50** is the negative log of the IC50 value. It is easy for the interpretation and common to measure the potency of compounds (Please refer to [talktorial 001](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T001_query_chembl/talktorial.ipynb) for further details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecule encoding\n",
    "\n",
    "For machine learning algorithms, molecules need to be converted into a list of features, in this case molecular fingerprints are used. \n",
    "\n",
    "Molecular fingerprints represents or encoded the chemical structures and molecular features in bitstrings form, where at each position \"1\" represents the presence and \"0\" represents the absence of a feature.\n",
    "\n",
    "One of the common fingerprints used is **M**olecular **ACC**ess **S**ystem fingerprints [(MACCS Keys)](https://docs.eyesopen.com/toolkits/python/graphsimtk/fingerprint.html#maccs) which are 166 bits structural key descriptors in which each bit is associated with a [SMARTS](https://docs.eyesopen.com/toolkits/python/oechemtk/glossary.html#term-smarts) pattern (Please refer to [talktorial 004](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T004_compound_similarity/talktorial.ipynb) for further details.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a neural network?\n",
    "\n",
    "Neural networks, also known as artificial neural networks (ANNs) are subset of machine learning algorithms. The structure and the name of the neural network is inspired by the human brain, mimicking the way that biological neurons transfers signal to one another.\n",
    "Artificial neural networks (ANNs) are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Neurons are the core processing unit of the network. The operations of a complete neural network is straightforward: input layer receives the input and the output layer predicts our final output. In between there exists hidden layers which performs the computations required by our network. \n",
    "\n",
    "Each node, or artificial neuron, connects to another via channels meaning a neuron of the column *n* can only be connected to neurons from column *n-1* and *n+1*. Every neural connection or channel has an associated numerical value known as weights. If the output of any individual neuron is above certain threshold value, that node is activated, meaning sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network. We will discuss more about the structure in the next section.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/neural_network.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 1:* Representation of a two-layer neural network. Figure is taken from the article [Coding Neural Network — Forward Propagation and Backpropagtion](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic structure of a neural network\n",
    "\n",
    "Neural network consists of three main layers as shown below:\n",
    "1. Input layer\n",
    "2. Hidden layers \n",
    "3. Output layer \n",
    "\n",
    "<div>\n",
    "<img src=\"images/basic_structure.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 2:* Figure shows the basic structure of a neural network. It is taken from the article: \"*Designing Your Neural Networks*\", Lavanya Shukla, [towardsdatascience](https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed)\n",
    "\n",
    "Lets take a deeper look at each layer,\n",
    "\n",
    "\n",
    "- **Input neurons or input layer**\n",
    "   - This layers represents the number of features which are used to make the predictions.\n",
    "   - The input vector needs one input neuron per feature. For example as shown in the figure below, the image is composed of 28 * 28 = 784 pixels, each pixel will be fed as input to each neuron of the first input layer.\n",
    "   \n",
    " \n",
    "<div>\n",
    "<img src=\"images/input_vector.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 3:* Figure shows a hand written digit composed of 784 pixels which is given as an input to our first input layer neurons. It is taken from the article: \"*Designing Your Neural Networks*\", Lavanya Shukla, [towardsdatascience](https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed)\n",
    "\n",
    "\n",
    "- **Hidden layers and neurons per hidden layers**\n",
    "    - The number of hidden layers and the neurons is totally dependent on the type of the problem and how much deep a neural network you want. In general, using same number of neurons for all hidden layers will suffice but for some datasets, having a large first layer and following it up with smaller layers will lead to a better performance as first layer can learn a lot of low-level features that can feed into the next subsequent layers which can learn higher order features.\n",
    "    - In the figure below, the input was a dog image broken into pixels, then several layers learn the different features and finally the network outputs it as a dog.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/layer.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 4:* Figure shows the hidden layers learning certain features of a dog image. It taken from the article: \"*Designing Your Neural Networks*\", Lavanya Shukla, [towardsdatascience](https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed)\n",
    "\n",
    "\n",
    "- **Output neurons or output layer**\n",
    "  - Output layer contains the number of neurons which represents the number of predictions you want to make and the neuron with highest value probability determines the output.\n",
    "  - **Regression**: For regressions tasks, this can be a value like predicting the price of the house or predicting stock prices.\n",
    "  - **Classification**: For binary classification tasks, we have output neuron per positive class which represents the probability of the positive class whereas for multi-class classification, we have an output neuron per class and we use the certain activation function on the output layer to ensure the final probabilities sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does a neuron do ?\n",
    "\n",
    "Neurons are the basic units of a neural network, so lets understand the operations done by each neuron:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/neuron.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 5:* Operations done by a neuron. Figure is taken from the artcile [First neural network for beginners explained (with code)](https://towardsdatascience.com/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf)\n",
    "\n",
    "- First, the values from the previous layer's neurons adds up and sent to the current neuron. In the figure above, there are 3 inputs (*X1, X2, X3*) coming to the neuron, meaning 3 neurons are connected to our current neuron. \n",
    "- Each connection or channel has assigned a numerical value known as **weight**(*w1, w2, w3*). Weight determines the connection between the neurons or in other words, a weight decides how much influence the input will have on the output. The inputs are multiplied by the corresponding weights and their sum is sent as input to the neurons in the hidden layer.\n",
    "- Each of these neurons is associated with a numerical value called the **bias** which is then added to the input sum.\n",
    "- Both weights and bias, commonly referred to as *w* and *b*, are the learnable parameters which can be tuned while training the model to get the better performance of a model. The equation below summarises the operations done by our neuron:\n",
    "\n",
    "$$Y = \\sum(w1*x1 + w2*x2 + w3*x3) + bias$$ \n",
    "\n",
    "- After all those summations, the value is then passed through a threshold function called the **activation function**. The result of the activation function determines if the particular neuron will get activated or not. An activated neuron transmits data to the neuron of the next layer over the channels. In this manner the data is propagated through the network which is known as **forward propagation**. There are many types of activation functions which we will discuss in detail in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function\n",
    "\n",
    "#### What is a activation function?\n",
    "\n",
    "[Activation function](https://en.wikipedia.org/wiki/Activation_function) are the mathematical equations that determine the output of a neural network. Each neuron is applied by this function and it determines whether the neuron should be activated or not. \n",
    "\n",
    "The value of **Y** can be anything ranging from -inf to +inf . The neuron doesn't know the bounds of the value, so how do we decide whether the neuron should be activated or not? Then, the activation functions comes into the picture which helps in normalizing the output of each neuron to a range between 1 and 0 or between -1 and 1 depending on the type of the activation function used. Activation function simply works as a \"gate\" in between the input feeding the current neuron and its output going to the next layer as shown below, \n",
    "\n",
    "<div>\n",
    "<img src=\"images/activation.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 6:* Figure shows the activation function applied on a neuron. It is taken from the blogpost: [7 Types of Neural Network Activation Functions: How to Choose?](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of activation function\n",
    "\n",
    "Activation functions can be basically divided into 3 types:\n",
    "\n",
    "##### Binary step function:\n",
    "\n",
    "It is a threshold-based activation function. Activation functions can be as simple as a [step function](https://en.wikipedia.org/wiki/Step_function) that turns the neuron's output \"on\" or simply neuron is activated when the **Y** value is above threshold, otherwise its \"off\". Simply put in an equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Activation function(A)} = \\text{\"activated\" if Y > threshold, else not}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Alternatively, A = 1 if Y > threshold, 0 otherwise}\n",
    "\\end{equation}\n",
    "\n",
    "<div>\n",
    "<img src=\"images/step.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 7:* Representation of a step function. Figure is take from the blogpost: [7 Types of Neural Network Activation Functions: How to Choose?](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/)\n",
    "\n",
    "Step function can work great with binary classifiers but it does not allow multi-value output for examples if we want to build a multi-class classifier model, we would want the network to activate only 1 neuron and others should be 0 but it won't be possible with a step function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear activation function: \n",
    "\n",
    "A linear activation function takes the form:\n",
    "$$\\boxed{A = cx}$$\n",
    "\n",
    "<div>\n",
    "<img src=\"images/linear.png\" width=\"300\"/>. \n",
    "</div>\n",
    "\n",
    "*Figure 8:* Representation of a linear activation function. Figure is take from the blogpost: [7 Types of Neural Network Activation Functions: How to Choose?](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/) \n",
    "\n",
    "It is a straight line function where the activation is proportional to input which is the weighted sum from neuron. It is better than a step function function because it gives range of activations, meaning multiple output is possible not just yes or no. But it also has some limitations:\n",
    "\n",
    "1. **Not possible to use backpropagation(gradient descent)** to train the model because the derivative of a linear function is a constant and has no relation with input so it is not possible to go back and tune weights in the network.\n",
    "\n",
    "2. **All layers will collapse into one**, with linear activation functions, no matter how many layers are the there in the neural network, if all are linear in nature, the final layer will be a linear functions of the first layer because a linear combination of linear functions will still be a linear function.\n",
    "That means two layers or N layers can be replaced by a single layer, so a linear activation function will turn the whole neural network into just one layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-linear activation function:\n",
    "\n",
    "Non-linear function addressed the problems of a linear activation function. Most neural networks uses non-linear activation functions as it makes easy for the model to generalize or adapt with variety of data and to differentiate between the output.\n",
    "\n",
    "There are many types of non-linear activation functions, we will discuss 4 most commonly used activation function (you can also refer the supplementary section to see how the functions are defined and plotted).\n",
    "\n",
    "\n",
    "1) **Sigmoid function (σ)**: It takes the form: $$\\boxed{f(x)=\\frac{1}{1+e^{−x}}}$$ \n",
    "\n",
    "   -  The sigmoid curve looks like a *S*-shaped curve as shown in the figure below. \n",
    "   - It has a \"smooth gradient\" which prevents jumps in the output values and it bound the output values between 0 and 1.\n",
    "   - It's recommended to be used only on the output layer so that we can easily interpret the output as probabilities since it has restricted output between 0 and 1. \n",
    "   - If you notice in the figure below, x values between -2.5 to 2.5, Y values are very steep, so any small change in values of x in that region will cause value of y to change significantly. It tends to bring the activations to either side of the curve.\n",
    "   - Another advantage of this activation function, unlike linear function, the output of the activation function is always going to be in range (0,1) compared to (-inf, inf) of linear function.\n",
    "   - But it has a major drawback, for very high or very low values of X, there is almost no change in y values or the prediction, causing a [**vanishing gradient**](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) problem. This can cause the network to learn slowly or refuses to learn further. \n",
    "     \n",
    "<div>\n",
    "<img src=\"images/sigmoid.png\" width=\"400\" >\n",
    "</div>\n",
    "\n",
    "*Figure 9:* Representation of a \"sigmoid\" function. Figure by Sakshi Misra.\n",
    "\n",
    "\n",
    "\n",
    "2) **Hyperbolic Tangent function or TanH**:  It takes the form: $$\\boxed{f(x)= tanh(x) = \\frac{2}{1+e^{-2x}}−1}$$ it looks very similar to sigmoid function, it can also be written as $$\\boxed{tanh(x)= \\text{2 sigmoid (2x)}-1}$$\n",
    "\n",
    "   - It has same characteristics as sigmoid like non-linear in nature, output is bound between -1 and 1 but it has deeper [derivative s](https://en.wikipedia.org/wiki/Derivative) which means it has stronger gradient than sigmoid as shown in the figure below. Deciding between sigmoid and tanh depends upon your requirement of gradient strength.\n",
    "   - The disadvantage that it shares with sigmoid function is that the it also has vanishing gradient problem.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/tanh.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 10:* Representation of a \"tanh\" function. Figure by Sakshi Misra\n",
    "\n",
    "\n",
    "3) **Rectified Linear Unit (ReLU)**: ReLu takes the form: $$\\boxed{f(x) = max\\{ 0,x\\}}$$\n",
    "\n",
    "  - As shown below, ReLu gives an output *x* if *x* is positive and *0* otherwise.\n",
    "  - It is not bound though. The range of ReLu is [0, inf).\n",
    "  - The only issue is that when inputs approach to zero or negative, the gradient of the function becomes zero hence, the network cannot learn and perform backpropagation.\n",
    "  - ReLU is the most commonly used activation function, one of the reasons could be its sparsity in the activation. Imagine if we have a deep neural network with many neurons, using a sigmoid of tanh will cause all the neurons to be activated, this is costly. But with ReLu, only few neurons will be activated and thereby making the activations sparse and efficient.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/relu.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 11:* Representation of a \"ReLU\" function. Figure by Sakshi Misra\n",
    "\n",
    "\n",
    "4) **Leaky Rectified Linear Unit**: ReLu takes the form: $$\\boxed{f(x)= \\max\\{ α ∗ x,x\\}}$$\n",
    "\n",
    "   - This is the variation of ReLU which has a small positive slope in the negative area.\n",
    "   - The range of the Leaky ReLU is (-infinity to infinity).\n",
    "   - It overcomes the zero gradient issue from ReLU and assigns α which is a small value for x≤0.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/leaky.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "*Figure 12:* Representation of a \"Leaky ReLU\" function. Figure by Sakshi Misra\n",
    "\n",
    "\n",
    "Now which activation function do we choose? It totally depends on the type of the problem you are solving, you can choose an activation function which will approximate the function faster and lead to faster raining process. There are other activation functions too, but the general idea remains the same. Please refer [Review paper](https://papers.nips.cc/paper/1993/file/51ef186e18dc00c2d31982567235c559-Paper.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function \n",
    "\n",
    "Before diving into how to train a neural network lets discuss about **loss** and **loss function**. In neural network, we an objective function i.e. to minimize the prediction error, so this objective function is often referred to as cost function or loss function. Through loss function we calculate loss or prediction error basically. Loss function is one of the important components of training the neural networks. \n",
    "\n",
    "Keras and tensorflow have various inbuilt loss functions, we will be covering some of them:\n",
    "\n",
    "- **Mean Squared Error (MSE)**: It is used for regression tasks, as the name suggests this loss is calculated by taking the mean of squared differences between actual(target) and predicted values. \n",
    "\n",
    "- **Binary Crossentropy (BCE)**: BCE loss is used for the binary classification tasks. We just need one output node to classify the data into two classes. The output value should be passed through a sigmoid activation function and the range of output is (0 – 1)\n",
    "\n",
    "- **Categorical Crossentropy (CC)**: When we have a multi-class classification task, we can use CC loss function. If we are using CCE loss function, there must be the same number of output nodes as the classes. And the final layer output should be passed through a softmax activation so that each node output a probability value between (0–1).\n",
    "\n",
    "\n",
    "The choice of loss function is directly related to the activation function used in the output layer of your neural network. For example, in our case we have to predict the pIC50 value of drug molecules so it is a regression task. We can use linear activation function in the output layer and mean square error (mse) as our loss function.\n",
    "\n",
    "You can refer to article: [Loss and Loss Functions for Training Deep Learning Neural Networks](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train a neural network ?\n",
    "\n",
    "When we start with **[forward propagation](https://en.wikipedia.org/wiki/Feedforward_neural_network)**, we randomly assign weights in our network. Obviously, it won’t give very good results, so how the network figures this out? \n",
    "\n",
    "During the training process along with the input our network also has the output fed to it. The predicted output is compared against the actual output to realize the error in prediction, the magnitude of the error indicates how wrong we are. This error is computed using loss function which we want to minimize and make it much lower at the end of training. It can be done by calculating the gradient by back propagating in the network and adjust the weights such that the network can predict the output correctly. \n",
    "\n",
    "There are major two algorithms which helps in training the neural network model:\n",
    "\n",
    "- [Back propagation](https://de.wikipedia.org/wiki/Backpropagation): gradient computation  \n",
    "- [Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent#:~:text=Gradient%20descent%20is%20a%20first,the%20direction%20of%20steepest%20descent.): optimization method to minimize the loss or cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation\n",
    "\n",
    "Backpropagation is an efficient method of calculating the derivatives or gradient. This algorithm trains a neural network through a method called chain rule. In simple terms, after each forward pass through a network, backpropagation performs a backward pass while adjusting the model’s parameters (weights and biases) which aims to minimize the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent \n",
    "\n",
    "Gradient is the vector which points to the direction of the steepest increase of the function. Since, we want to minimize our function, we will take a step in the opposite direction of gradient. Generally we want to control how big of step we make, this is achieved by choosing the most important hyper parameter which is called [learning rate](https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b). Mostly people choose learning rate by trying out a bunch of numbers and using the one that looks to work best. \n",
    "\n",
    "In our neural network we have weights which values we want to improve, if we compute the gradient of the loss function w.r.t. to our weights and take small steps in the opposite direction of gradient, our loss will gradually decrease until it converges to some local minima, this algorithm is called gradient descent. So in short, it is the process of descending through the gradient i.e. adjusting the parameters of the model to minimize the loss function and achieve our target, which is to predict close to the original value. There many types of gradient descent method:\n",
    "\n",
    "- **Stochastic Gradient Descent(SGD)**: When we train the model to optimize the loss function using only single sample from our dataset, it is called Stochastic Gradient Descent.\n",
    "- **Batch Gradient Descent**: When we train the model to optimize the loss function using the the whole dataset, it is called Batch Gradient Descent.\n",
    "- **Mini-Batch Gradient Descent**: Batch gradient descent takes a lot of time and is therefore somewhat inefficient. If we look at SGD, it is trained using only 1 example. There is a possibility that the model may get too biased with the peculiarity of that particular example when we use SGD. So, we use the mean of a batch of 10–1000 examples to check the optimize the loss in order to deal with the problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of neural network\n",
    "\n",
    "We will focus on major three important types of neural networks:\n",
    "- Artificial Neural Networks (ANN)\n",
    "- Convolution Neural Networks (CNN)\n",
    "- Recurrent Neural Networks (RNN)\n",
    "\n",
    "Lets discuss each neural network in detail.\n",
    "\n",
    "#### Artificial Neural Networks (ANN)\n",
    "\n",
    "It is also known as feed-forward neural network because inputs are processed only in the forward direction. The information flow in this network is unidirectional. We have already discussed above about the basic structure and working of the artificial neural network and we will implement the same in the practical part below. \n",
    "\n",
    "There are some challenges faced  with ANN such as: \n",
    "- ANN cannot capture sequential information in the input data which is required for dealing with sequence data\n",
    "- One common problems with all neural networks is the vanishing and exploding gradient\n",
    "- While solving an image classification problem, the 2D image is converted into 1D which makes number of trainable parameters drastically increases with the size of the image. \n",
    "\n",
    "\n",
    "#### Recurrent Neural Networks (RNN)\n",
    "\n",
    "Let us first try to understand the difference between RNN and ANN\n",
    "<div>\n",
    "<img src=\"images/RNN.png\" width=\"300\"/>\n",
    "</div> \n",
    "\n",
    "*Figure 13:* Figure shows the difference between RNN and ANN. It is taken from the blogpost: [CNN vs. RNN vs. ANN – Analyzing 3 Types of Neural Networks in Deep Learning](https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/)\n",
    "\n",
    "As you can see, RNN has recurrent connection on the hidden state. They are bit more complex and the data flows in multiple direction. RNN overcomes some of the problem faced with ANN by capturing the sequential information present in the input data. It also shares parameters across different time steps which is known as **parameter sharing**. But RNNs also suffer from vanishing and exploding gradient.\n",
    "\n",
    "You can refer the article [Fundamentals of Deep Learning – Introduction to Recurrent Neural Networks] to learn more about how RNNs work and how to build one in Python.\n",
    "\n",
    "\n",
    "#### Convolution Neural Networks (CNN)\n",
    "\n",
    "CNNs are widely used neural networks especially for image and video processing tasks. **Filters** a.k.a. **kernels** are the building blocks of CNNs. They are used to extract the relevant features from the input data using the convolution operation. There are some major advantages of using CNN such as:\n",
    "- CNN learns the filters automatically without mentioning it explicitly. These filters help in extracting the right and relevant features from the input data.\n",
    "- CNN also helpful in capturing the **spatial features** which refers to the arrangement of pixels and the relationship between them in an image. These spatial features help us in identifying the object accurately.\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/1oB3S5yHHhvougJkPXuc8og.gif\" width=\"500\" align=\"center\">\n",
    "\n",
    "*Figure 14:* Gif represents the image classification using CNN. It is taken from the blogpost: [CNN vs. RNN vs. ANN](https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/)\n",
    "\n",
    "\n",
    "If you want to explore more about CNN, please refer to the article [Demystifying the Mathematics Behind Convolutional Neural Networks (CNNs)](https://courses.analyticsvidhya.com/courses/convolutional-neural-networks-cnn-from-scratch?utm_source=blog&utm_medium=cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and applications of neural network\n",
    "\n",
    "#### Advantages of a neural network \n",
    "\n",
    "- **Organic learning**: Neural networks have the ability to learn by themselves by extracting the important features present in the input data. The outputs aren't limited entirely by inputs. Neural networks have the ability to generalize their inputs.\n",
    "- **Non linear data processing**: They have the ability to learn and model non-linear and complex relationships. \n",
    "- **Fault tolerance**: They have potential for high fault tolerance. When these networks are scaled across multiple machines and multiple servers, they can debug and diagnose the problem by its own.\n",
    "\n",
    "\n",
    "#### Applications of neural networks\n",
    "\n",
    "There are various applications of neural networks in various fields such as:\n",
    "- Facial recognition\n",
    "- Language processing and translation\n",
    "- Route detection\n",
    "- Speech recognition\n",
    "- Forecasting\n",
    "\n",
    "Please refer to the article: \"*Neural networks – advantages and applications*\", [ScienceDirect](https://doi.org/10.1016/B978-0-444-81892-8.50036-5) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "The first step is to import all the necessary libraries and define the functions and classes we intend to use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, Draw\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# Neural network specific libraries\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "\n",
    "# Silence some expected warnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load data and visualize the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data which is the subset of ChEMBL dataset and visualize the dataframe, the important columns in the dataframe are:\n",
    "\n",
    "- CHEMBL-ID\n",
    "- SMILES string of the corresponding compound\n",
    "- Measured affinity: pIC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\"\n",
    "\n",
    "df = pd.read_csv(DATA/'CHEMBL25_activities_EGFR.csv',\n",
    "                 lineterminator='\\n') # NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe :  (3906, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3906 entries, 0 to 3905\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        3906 non-null   int64  \n",
      " 1   chembl_id         3906 non-null   object \n",
      " 2   IC50              3906 non-null   float64\n",
      " 3   units             3906 non-null   object \n",
      " 4   canonical_smiles  3906 non-null   object \n",
      " 5   pIC50\r",
      "            3906 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 183.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>IC50</th>\n",
       "      <th>units</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>pIC50\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1777</td>\n",
       "      <td>CHEMBL207869</td>\n",
       "      <td>77.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>Clc1c(OCc2cc(F)ccc2)ccc(Nc2c(C#Cc3ncccn3)cncn2)c1</td>\n",
       "      <td>7.113509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5785</td>\n",
       "      <td>CHEMBL3940060</td>\n",
       "      <td>330.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>ClCC(=O)OCCN1C(=O)Oc2c1cc1c(Nc3cc(Cl)c(F)cc3)n...</td>\n",
       "      <td>6.481486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6373</td>\n",
       "      <td>CHEMBL3678951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>FC(F)(F)c1cc(Nc2n(C(C)C)c3nc(Nc4ccc(N5CC[NH+](...</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2442</td>\n",
       "      <td>CHEMBL504034</td>\n",
       "      <td>40.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>Clc1c(OCc2cc(F)ccc2)ccc(Nc2ncnc3c2sc(C#C[C@H]2...</td>\n",
       "      <td>7.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084</td>\n",
       "      <td>CHEMBL158797</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>nM</td>\n",
       "      <td>S(Sc1n(C)c2c(c1C(=O)NCC(O)CO)cccc2)c1n(C)c2c(c...</td>\n",
       "      <td>4.366531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      chembl_id     IC50 units  \\\n",
       "0        1777   CHEMBL207869     77.0    nM   \n",
       "1        5785  CHEMBL3940060    330.0    nM   \n",
       "2        6373  CHEMBL3678951      1.0    nM   \n",
       "3        2442   CHEMBL504034     40.0    nM   \n",
       "4        1084   CHEMBL158797  43000.0    nM   \n",
       "\n",
       "                                    canonical_smiles   pIC50\\r  \n",
       "0  Clc1c(OCc2cc(F)ccc2)ccc(Nc2c(C#Cc3ncccn3)cncn2)c1  7.113509  \n",
       "1  ClCC(=O)OCCN1C(=O)Oc2c1cc1c(Nc3cc(Cl)c(F)cc3)n...  6.481486  \n",
       "2  FC(F)(F)c1cc(Nc2n(C(C)C)c3nc(Nc4ccc(N5CC[NH+](...  9.000000  \n",
       "3  Clc1c(OCc2cc(F)ccc2)ccc(Nc2ncnc3c2sc(C#C[C@H]2...  7.397940  \n",
       "4  S(Sc1n(C)c2c(c1C(=O)NCC(O)CO)cccc2)c1n(C)c2c(c...  4.366531  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension and missing value of the data \n",
    "print(\"Shape of dataframe : \", df.shape) \n",
    "df.info()\n",
    "\n",
    "# Look at head\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>pIC50\\r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL207869</td>\n",
       "      <td>Clc1c(OCc2cc(F)ccc2)ccc(Nc2c(C#Cc3ncccn3)cncn2)c1</td>\n",
       "      <td>7.113509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL3940060</td>\n",
       "      <td>ClCC(=O)OCCN1C(=O)Oc2c1cc1c(Nc3cc(Cl)c(F)cc3)n...</td>\n",
       "      <td>6.481486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL3678951</td>\n",
       "      <td>FC(F)(F)c1cc(Nc2n(C(C)C)c3nc(Nc4ccc(N5CC[NH+](...</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL504034</td>\n",
       "      <td>Clc1c(OCc2cc(F)ccc2)ccc(Nc2ncnc3c2sc(C#C[C@H]2...</td>\n",
       "      <td>7.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL158797</td>\n",
       "      <td>S(Sc1n(C)c2c(c1C(=O)NCC(O)CO)cccc2)c1n(C)c2c(c...</td>\n",
       "      <td>4.366531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chembl_id                                   canonical_smiles   pIC50\\r\n",
       "0   CHEMBL207869  Clc1c(OCc2cc(F)ccc2)ccc(Nc2c(C#Cc3ncccn3)cncn2)c1  7.113509\n",
       "1  CHEMBL3940060  ClCC(=O)OCCN1C(=O)Oc2c1cc1c(Nc3cc(Cl)c(F)cc3)n...  6.481486\n",
       "2  CHEMBL3678951  FC(F)(F)c1cc(Nc2n(C(C)C)c3nc(Nc4ccc(N5CC[NH+](...  9.000000\n",
       "3   CHEMBL504034  Clc1c(OCc2cc(F)ccc2)ccc(Nc2ncnc3c2sc(C#C[C@H]2...  7.397940\n",
       "4   CHEMBL158797  S(Sc1n(C)c2c(c1C(=O)NCC(O)CO)cccc2)c1n(C)c2c(c...  4.366531"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the necessary columns\n",
    "chembl_df = df[[\"chembl_id\", \"canonical_smiles\", \"pIC50\\r\"]]\n",
    "chembl_df.head()\n",
    "# NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### Molecule encoding\n",
    "Now we have to convert the SMILES string to numerical data so that we can perform machine learning algorithm on it and we can use already defined function `smiles_to_fp` from Talktorial **T007** which generate fingerprints from SMILES. \n",
    "There is a choice incorporated between **MACCS**, **morgan2** and **morgan3** but we will use MACCS fingerprints because MACCS keys are short (166 bit) as compared to others (2048 bit). (Please refer to [talktorial 007](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T007_compound_activity_machine_learning/talktorial.ipynb) for further details on the functions defined for molecule encoding. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "format": "row"
   },
   "outputs": [],
   "source": [
    "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
    "    \"\"\"\n",
    "    Encode a molecule from a SMILES string into a fingerprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        The SMILES string defining the molecule.\n",
    "\n",
    "    method : str\n",
    "        The type of fingerprint to use. Default is MACCS keys.\n",
    "\n",
    "    n_bits : int\n",
    "        The length of the fingerprint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        The fingerprint array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert smiles to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if method == \"maccs\":\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
    "    if method == \"morgan2\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits))\n",
    "    if method == \"morgan3\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 3, nBits=n_bits))\n",
    "    else:\n",
    "        # NBVAL_CHECK_OUTPUT\n",
    "        print(f\"Warning: Wrong method specified: {method}. Default will be used instead.\")\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe :  (3906, 167)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  157  158  159  160  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    1    1    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    1    1    1    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    1   \n",
       "\n",
       "   161  162  163  164  165  166  \n",
       "0    1    1    1    1    1    0  \n",
       "1    1    1    1    1    1    0  \n",
       "2    1    1    1    0    1    0  \n",
       "\n",
       "[3 rows x 167 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all SMILES strings to MACC fingerprints\n",
    "fingerprints_df = pd.DataFrame([smiles_to_fp(smile) for smile in chembl_df['canonical_smiles']])\n",
    "\n",
    "# Look at head\n",
    "print(\"Shape of dataframe : \", fingerprints_df.shape)\n",
    "fingerprints_df.head(3) # NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define **X** and **y** which are the features used to train the model and target values respectively. In our case, features are the bit vectors and the target value is pIC50 values of the drug molecules which we want to predict.\n",
    "\n",
    "After defining X and y, we can use `train_test_split` from scikit-learn library to split the data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data :  (2734, 167)\n",
      "Shape of testing data :  (1172, 167)\n"
     ]
    }
   ],
   "source": [
    "# Assign X and y value\n",
    "X = fingerprints_df\n",
    "y = chembl_df[['pIC50\\r']]\n",
    "\n",
    "# Split the data into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shape of training and testing data\n",
    "print(\"Shape of training data : \", X_train.shape)\n",
    "print(\"Shape of testing data : \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use [keras](https://keras.io/getting_started/) to define our neural network model. Goal is to train a neural network model with the training dataset and use test datasets to predict the pIC50 value for the drug molecules which it has never seen before.\n",
    "\n",
    "We start by **defining** a keras model which is defined as a sequence of layers. We create a [Sequential model](https://keras.io/api/models/sequential/) and add layers. We can specify the number of neurons or nodes in the layer as the first argument, and specify the activation function using the activation argument. We have used [rectified linear unit activation function](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) in the hidden layers and linear in the output layer. \n",
    "\n",
    "Now, after defining the model, we can [compile](https://keras.io/api/models/model_training_apis/#compile-method) it. It uses the efficient numerical libraries to chooses the best way to represent the network for training and making predictions. When compiling we have to specify some additional parameters such as optimizer, loss, metrices etc. we would like to report. \n",
    "\n",
    "In this case we used **mean square error** as a loss argument and we defined optimizer to be **adam** which is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems. \n",
    "\n",
    "To learn more about the Adam version of stochastic gradient descent see the post: [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).\n",
    "\n",
    "Finally, we will report mean square error(mse) and mean absolute error(mae) as our metrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(hidden1, hidden2):\n",
    "    \"\"\"\n",
    "    creating neural network from two hidden layer\n",
    "    using relu as activation function in two hidden layer\n",
    "    and linear in the output layer\n",
    "\n",
    "    parameters\n",
    "    ----------\n",
    "    hidden1 : Int\n",
    "         number of neuons in first hidden layer\n",
    "\n",
    "    hidden2: Int\n",
    "         number of neuons in second hidden layer\n",
    "         \n",
    "    Returns\n",
    "    --------\n",
    "    model\n",
    "        fully connected neural network model with two hidden layer\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    # first hidden layer\n",
    "    model.add(Dense(hidden1, activation='relu', name=\"layer1\"))\n",
    "    # second hidden layer\n",
    "    model.add(Dense(hidden2, activation='relu', name=\"layer2\"))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='linear', name=\"layer3\"))\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the most appropriate batch sizes \n",
    "\n",
    "**Bath sizes** refers to the number of samples that will be propagated through the network to train it. \n",
    "Batches can made up of:\n",
    "- **Batch Gradient Descent**: when all training datasets is used as a batch.\n",
    "- **Stochastic Gradient Descent**: when single sample is used as a batch.\n",
    "- **Mini-Batch Gradient Descent**: when batch size is more than one sample but less that full training data.\n",
    "\n",
    "We have tried passing mini batches and plotted the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trying different batch sizes\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "# size of figure\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "sns.set(color_codes=True)\n",
    "for index in range(0, 5):\n",
    "    fig.add_subplot(2, 3, index+1)\n",
    "    model = NN_model(64, 32)\n",
    "# fit model on X_train and y_train data\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        batch_size = batch_sizes[index],\n",
    "                        validation_data = (X_test, y_test),\n",
    "                        verbose=0, epochs = 100)\n",
    "\n",
    "    plt.plot(history.history['loss'], label = 'train')\n",
    "    plt.plot(history.history['val_loss'], label = 'test')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('model loss in batch size = '+str(batch_sizes[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit keras model\n",
    "\n",
    "Now we will call [model.fit()](https://keras.io/api/models/model_training_apis/#fit-method) method which needs several parameters like **x**: Input data, **y**: Target data, batch size, epochs etc.\n",
    "We specified batch size to be 512 and epochs to be 100. \n",
    "\n",
    "One **epoch** means when an entire dataset is passed forward and backward through the neural network **once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filepath = \"weights_CV.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0,\n",
    "                             save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=100, batch_size=512, \n",
    "          callbacks=callbacks_list, verbose=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate keras model\n",
    "\n",
    "After training the model, we can use [model.evaluate()](https://keras.io/api/models/model_training_apis/#evaluate-method) to check the performance or score of our model. It will report the loss, mse and mae values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the model on training datausing `evaluate`\n",
    "print(\"Evaluate on training data\")\n",
    "score = model.evaluate(X, y, verbose=0 )\n",
    "print(f'score:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data\n",
    "\n",
    "#### Loading the test data (EGFR_test_set.csv)\n",
    "\n",
    "We will use another dataset to test the model. This dataset contains some SMILES compounds without the pIC50 values, we can load the dataset using pandas and visualize the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_df = pd.read_csv(DATA/'test.csv',\n",
    "                 lineterminator='\\n') # NBVAL_CHECK_OUTPUT\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same `smiles_to_fp` function and convert the SMILES strings in test data into MACCS fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all smiles in test file to MACC keys\n",
    "maccs_test_df = pd.DataFrame([smiles_to_fp(smile) for smile in test_df['canonical_smiles\\r']])\n",
    "maccs_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can use [model.predict](https://keras.io/api/models/model_training_apis/#predict-method) to predict the pIC50 values of test molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "pred = model.predict(maccs_test_df)\n",
    "\n",
    "predicted_pIC50 = pd.DataFrame(pred, columns=['Predicted pIC50 values'])\n",
    "predicted_pIC50_df = test_df.join(predicted_pIC50 )\n",
    "\n",
    "predicted_pIC50_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation on test data \n",
    "print(\"Evaluate on test data\")\n",
    "score = model.evaluate(maccs_test_df, pred)\n",
    "print(f'score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting to compare the distribution of pIC50 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot to compare the distribution \n",
    "# of training pIC50 values and the predected pIC50 \n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(predicted_pIC50_df[\"Predicted pIC50 values\"],\n",
    "         facecolor='b', histtype='barstacked', range=(1, 10))\n",
    "plt.xlabel('pIC50 values')\n",
    "plt.ylabel('count')\n",
    "plt.title('range of predicted pIC50')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(chembl_df[\"pIC50\\r\"], facecolor='r', range=(1, 10), bins=10)\n",
    "plt.xlabel('pIC50 values')\n",
    "plt.ylabel('count')\n",
    "plt.title('range of pIC50 value used in training the model')\n",
    "plt.show()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO We can see the predicted values are also right skewed and the training values are also right skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "- TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "## Supplementary section\n",
    "\n",
    "In this section we have defined activation functions and forward propagation function for better understanding of the concept.\n",
    "\n",
    "We have defined 4 activation functions which were discussed in the theory section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activation functions that can be used in forward propagation\n",
    "def sigmoid(input_array):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of input element-wise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : array\n",
    "             input values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Activation_function : array\n",
    "             post activation output.\n",
    "    input_array : array\n",
    "             input values.\n",
    "    \"\"\"\n",
    "    Activation_function = 1 / (1 + np.exp(-input_array))\n",
    "\n",
    "    return Activation_function, input_array\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    \"\"\"\n",
    "    Computes the Hyperbolic Tagent of input element-wise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : array\n",
    "             input values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Activation_function : array\n",
    "             post activation output.\n",
    "    input_array : array\n",
    "             input values.\n",
    "    \"\"\"\n",
    "    Activation_function = np.tanh(input_array)\n",
    "\n",
    "    return Activation_function, input_array\n",
    "\n",
    "\n",
    "def relu(input_array):\n",
    "    \"\"\"\n",
    "    Computes the Rectified Linear Unit (ReLU) element-wise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : array\n",
    "             input values.\n",
    "    Returns\n",
    "    -------\n",
    "    Activation_function : array\n",
    "             post activation output.\n",
    "    input_array : array\n",
    "             input values.\n",
    "    \"\"\"\n",
    "    Activation_function = np.maximum(0, input_array)\n",
    "\n",
    "    return Activation_function, input_array\n",
    "\n",
    "\n",
    "def leaky_relu(input_array):\n",
    "    \"\"\"\n",
    "    Computes Leaky Rectified Linear Unit element-wise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_array : array\n",
    "             input values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Activation_function : array\n",
    "             post activation output.\n",
    "    input_array : array\n",
    "             input values.\n",
    "    \"\"\"\n",
    "    Activation_function = np.maximum(0.1 * input_array, input_array)\n",
    "\n",
    "    return Activation_function, input_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot all the activation function using `matplotlib.plt` library as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 4 activation functions\n",
    "input_array = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Computes post-activation outputs\n",
    "A_sigmoid, input_array = sigmoid(input_array)\n",
    "A_tanh, input_array = tanh(input_array)\n",
    "A_relu, input_array = relu(input_array)\n",
    "A_leaky_relu, input_array = leaky_relu(input_array)\n",
    "\n",
    "# Plot sigmoid function\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(input_array, A_sigmoid,'b')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.axhline(y=0, color='gray',linestyle='--')\n",
    "plt.xlabel(\"input(x)\")\n",
    "plt.ylabel(r\"$\\frac{1}{1 + e^{-x}}$\")\n",
    "plt.title(\"Sigmoid Function\", fontsize = 16)\n",
    "\n",
    "# Plot tanh function\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(input_array, A_tanh, 'b')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.axhline(y=0, color='gray',linestyle='--')\n",
    "plt.xlabel(\"input(x)\")\n",
    "plt.ylabel(r\"$\\frac{e^x - e^{-x}}{e^x + e^{-x}}$\")\n",
    "plt.title(\"Hyperbolic Tangent Function\", fontsize = 16)\n",
    "\n",
    "# plot relu function\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(input_array, A_relu, 'b')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.axhline(y=0, color='gray',linestyle='--')\n",
    "plt.xlabel(\"input(x)\")\n",
    "plt.ylabel(r\"$max\\{0, x\\}$\")\n",
    "plt.title(\"ReLU Function\", fontsize = 16)\n",
    "\n",
    "# plot leaky relu function\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(input_array, A_leaky_relu, 'b')\n",
    "plt.axvline(x=0, color='gray', linestyle='--')\n",
    "plt.axhline(y=0, color='gray',linestyle='--')\n",
    "plt.xlabel(\"input(x)\")\n",
    "plt.ylabel(r\"$max\\{0.1x, x\\}$\")\n",
    "plt.title(\"Leaky ReLU Function\", fontsize = 16)\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define forward propagation function using classes, this implementation can help you understand the concept practically.\n",
    "\n",
    "First we converted our input bit vectors data into lists and then defined a class named `Layer_Dense`. It has two properties, weights and biases. We have randomly assigned their values and defined a function named `forward_pass` which calculates the **dot product** of the input values and weights and add it to the bias values. \n",
    "\n",
    "Now, as we know activation function is applied on every neuron, so we have created another class named `activation_function`, here we have defined the a function named `ReLU`, meaning we will use ReLU activation function in this case. \n",
    "\n",
    "After defining classes and their attributes, we create an object from both the classes and called the functions on our data. We can now print the output values as shown.\n",
    "\n",
    "**Note:** The predicted values will differ in every run because the weights are randomly assigned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our input data to list\n",
    "fingerprints_df_list = fingerprints_df.values.tolist()\n",
    "\n",
    "# create forward pass function with one hidden layer\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward_pass(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "\n",
    "class Activation_function:\n",
    "    def ReLU(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "\n",
    "# object        \n",
    "layer1 = Layer_Dense(167, 50)\n",
    "layer2 = Layer_Dense(50, 1)\n",
    "activation1 = Activation_function()\n",
    "activation2 = Activation_function()\n",
    "\n",
    "# function calling\n",
    "layer1.forward_pass(fingerprints_df_list)\n",
    "layer2.forward_pass(layer1.output)\n",
    "activation1.ReLU(layer1.output)\n",
    "activation2.ReLU(layer2.output)\n",
    "\n",
    "print(activation2.output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
