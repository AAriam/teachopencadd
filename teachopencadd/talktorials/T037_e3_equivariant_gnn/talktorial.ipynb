{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T037 · An introduction to $\\text{E}(3)$-invariant graph neural networks\n",
    "\n",
    "**Note:** This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects.\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Joschka Groß, 2022, Chair for Modelling and Simulation, Saarland University"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "This talktorial is supposed to serve as an introduction to machine learning on point cloud representations of molecules with 3D conformer information, i.e., molecular graphs that are embedded into Euclidean space (see **Talktorial 033**). You will learn why Euclidean equivariance and invariance are important properties of neural networks (NNs) that take point clouds as input and learn how to implement and train such NNs. In addition to discussing them in theory, this notebook also aims to demonstrate the shortcomings of plain graph neural networks (GNNs) when working with point clouds practically."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Theory*\n",
    "\n",
    "* Why 3D coordinates?\n",
    "* Representing molecules as point clouds\n",
    "* Equivariance and Invariance in euclidean space and why we care\n",
    "* How to construct $\\text{E}(n)$-invariant and equivariant models\n",
    "* The QM9 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Practical*\n",
    "\n",
    "* Visualization of point clouds\n",
    "* Set up and inspect the QM9 dataset\n",
    "  * Preprocessing\n",
    "  * Atomic number distribution and point cloud size\n",
    "  * Data split, distribution of regression target electronic spatial extent\n",
    "* Model implementation\n",
    "  * Plain \"naive Euclidean\" GNN\n",
    "  * Demo: Plain GNNs are not E(3)-invariant\n",
    "  * EGNN model\n",
    "  * Demo: Our EGNN is E(3)-invariant\n",
    "* Training and evaluation\n",
    "  * Setup\n",
    "  * Training the EGNN\n",
    "  * Training the plain GNN\n",
    "  * Comparative evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References\n",
    "\n",
    "#### Theoretical\n",
    "* **Quantum chemistry structures and properties of 134k molecules (QM9)**: [<i>Scientific data</i> (2014)](https://www.nature.com/articles/sdata201422/?ref=https://githubhelp.com)\n",
    "* **MoleculeNet: a benchmark for molecular machine learning**: [<i>Chem. Sci.</i>, 2018, <b>9</b>, 513-530](https://pubs.rsc.org/en/content/articlehtml/2018/sc/c7sc02664a)\n",
    "* **$\\text{E}(n)$ Equivariant Graph Neural Networks**: [<i>International conference on machine learning</i> (2021), <b>139</b>, 99323-9332](https://proceedings.mlr.press/v139/satorras21a.html)\n",
    "* **SE(3)-transformers: 3D roto-translation equivariant attention networks**: [<i>Advances in Neural Information Processing Systems</i> (2021), <b>33</b>, 1970-1981](https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf)\n",
    "* **TorchMD-NET: Equivariant Transformers for Neural Network based Molecular Potentials**: [<i>arXiv preprint (2022)</i>](https://arxiv.org/abs/2202.02541)\n",
    "* **DiffDock**: [<i> arXiv preprint</i> (2022)](https://arxiv.org/abs/2210.01776)\n",
    "\n",
    "#### Practical\n",
    "* [Pytorch Geometric QM9 version](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why 3D coordinates?\n",
    "\n",
    "* Some properties are more easily derived when 3D coordinates are known.\n",
    "* Sometimes the task is to predict properties that are directly linked to Euclidean space, e.g. future atom positions or forces that apply to atoms.\n",
    "* Compared to molecular graph representations, we in principle only gain information. Covalent bonds can still be inferred from atom types and positions because they can be attributed to overlapping atomic orbitals. Note that one could still include structural information s.t. the model does not have to learn this information itself\n",
    "\n",
    "\n",
    "An example CADD application that may require the use of 3D coordinates is protein-ligand docking (see **Talktorial 015**). [Recent work from 2022](https://arxiv.org/abs/2210.01776) uses E(3) equivariant graph neural networks as the backbone for a generative model that learns to predict potential ligand docking positions (3D coordinates for the atoms of a given ligand) when additionally given protein structures with 3D information as input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecules as point clouds: mathematical background\n",
    "In this talktorial we will focus on atoms and their 3D positions and ignore structural (bond) information. Our mathematical representations of a molecule is thus a point cloud (also see **Talktorial 33**), i.e., a tuple $(X, Z)$ where $Z \\in \\mathbb{R}^{m \\times d}$ is a matrix of $m$ atoms represented by $d$ features each and $X \\in \\mathbb{R}^{m \\times 3}$ captures the atom 3D coordinates. We will assume that the coordinates correspond to a specific molecular conformation (see **Talktorial 033**) of the molecule."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivariance and Invariance in Euclidean space and why we care\n",
    "When representing molecules as graphs equi- and/or invariance w.r.t. to node permutations are desirable model properties (**Talktorial 33/34**). When working with point clouds, i.e., when atoms/nodes are embedded into Euclidean space, we should also be concerned about Euclidean symmetry groups. These are groups of transformations $g: \\mathbb{R}^n \\to \\mathbb{R}^n$ that preserve distance, i.e., translations, rotations, reflections, or combinations thereof. For the Euclidean space $\\mathbb{R}^n$ with $n$ spatial dimensions, one typically distinguishes between\n",
    "* the Euclidean group $\\text{E}(n)$, which consists of *all* distance-preserving transformations, and\n",
    "* the special Euclidean group $\\text{SE}(n)$, which consists only of translations and rotations.\n",
    "  \n",
    "Say $\\theta$ is a model that learns atom embeddings $H = \\theta(X, Z) \\in \\mathbb{R}^{m \\times q}$ where $q$ is the number of embedding dimensions. We call $\\theta$ $\\text{E}(n)$-*invariant*, if for all $g \\in \\text{E}(n)$\n",
    "$$\n",
    "\\theta(g(X), Z) = \\theta(X, Z),\n",
    "$$\n",
    "where $g$ is applied row-wise to $X$. Put simply the output of $\\theta$ remains unaffected, no matter how we rotate, translate, or reflect the molecule.\n",
    "\n",
    "If we consider a model that makes predictions about objects which are coupled to the Euclidean space $X' = \\theta(X, Z) \\in \\mathbb{R}^{m \\times n}$ (e.g. future atom positions in a dynamical system), we can define $\\text{E}(n)$-*equivariance* as\n",
    "$$\n",
    "\\theta(g(X), Z) = g(\\theta(X, Z)),\n",
    "$$\n",
    "for all $g \\in \\text{E}(n)$ applied in row-wise fashion. This is saying that the output of $\\theta$ is transformed in the same way as its input. Note that this definition can easily be extended to arbitrary Euclidean features (velocities, electromagnetic forces, ...).\n",
    "\n",
    "So, why do we care about these properties?\n",
    "\n",
    "Let's assume our goal was to train a model that predicts the docking position of a ligand when given a fixed protein structure, also with 3D coordinates. Would you trust a model that predicted different relative positions for the ligand atoms when the protein was simply rotated by 180 degrees? If your answer is no, then you should consider using a model that is at least $\\text{SE}(3)$-equivariant.\n",
    "In addition to being a \"natural\" choice given such considerations, euclidean equivariance empirically also increases the sample complexity (efficiency) of training and improves the model's ability to generalize to unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To sum up** it may be helpful to address the problem from a slightly different point of view: Point clouds as representations for molecular conformations are *not unique*. In fact, for one molecular conformation, there are *infinitely many* valid point cloud representations. If $(X, Z)$ is such a representation then $(g(X), Z)$ with $g \\in \\text{E}(3)$ is too and there are infinitely many such $g$. All $\\text{E}(3)$-invariance and equivariance are thus saying, is that our machine learning models *should not care* which of these representations we end up using.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>![Figure title](images/2d_rotation_equivariance.png)</code>\n",
    "\n",
    "*Figure 1:* \n",
    "An illustration of a 2D-rotationally equi- and invariant transformation $\\phi$.\n",
    "Taken from [the EGNN paper by Satoras et. al.](https://proceedings.mlr.press/v139/satorras21a.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to construct $\\text{E}(n)$-invariant and equivariant models\n",
    "\n",
    "Constructing such models is simple if we focus on the fact that all $g \\in \\text{E}(n)$ are *distance-preserving*. We will not give a [fully-fledged proof](https://proceedings.mlr.press/v139/satorras21a.html), but it should not come as a great surprise that a model which *only considers relative distances between atoms* for computing node (atom) embeddings is guaranteed to be $E(n)$-invariant. We can thus define a *message passing network* $\\theta(Z, X)$ with $l=1,\\ldots,L$ layers where\n",
    "\n",
    "\\begin{align*}\n",
    "    h_{i}^0 &= \\psi_0(Z_i) && (1)\\\\\n",
    "    d_{ij} &= ||X_i - X_j||^2 && (2) \\\\\n",
    "    m_{ij}^{l} &= \\phi_{l}(h_i^l, h_j^l, d_{ij})  ~~\\text{for}~l=0,\\ldots,L-1 && (3)\\\\\n",
    "    h_{i}^{l+1} &= \\psi_l(h_{i}^l, \\sum_{j \\neq i} m_{ij}^l) ~~\\text{for}~l=0,\\ldots,L-1 && (4)\n",
    "\\end{align*}\n",
    "\n",
    "and $\\psi_0$ computes the initial node embeddings, the $\\phi_l$ MLPs $\\text{}^1$ construct messages and $\\psi_l$ MLPs take care of combining previous embeddings and aggregated messages into new embeddings. The final node embeddings $H = (h_1^L \\ldots h_n^L)^t$ computed by this scheme are $E(n)$-invariant.\n",
    "\n",
    "\n",
    "In the practical part, we will only predict properties that are not directly linked to the Euclidean space, so this kind of network suffices for our purposes. If your goal is to predict e.g. atom positions, you will need to define additional, slightly more sophisticated transformations to ensure that they are $E(3)$-equivariant, but they usually follow the same principle of only using distances in their computations. If you want to read up on this you can take a look at these papers\n",
    "* [$\\text{E}(n)$ Equivariant Graph Neural Networks](https://proceedings.mlr.press/v139/satorras21a.html)\n",
    "* [$SE(3)$ Transformer](https://proceedings.neurips.cc/paper/2020/file/15231a7ce4ba789d13b722cc5c955834-Paper.pdf)\n",
    "* [TorchMD-Net](https://arxiv.org/abs/2202.02541)\n",
    "\n",
    "\\\n",
    "\\\n",
    "$~^1$ multi-layer perceptrons (MLPS) are stacks of multiple fully connected layers with non-linear activation functions (also see **Talktorial 022**)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QM9 dataset\n",
    "\n",
    "The QM9 dataset [$^1$](https://www.nature.com/articles/sdata201422/?ref=https://githubhelp.com) [$^2$](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9) is part of the [MoleculeNet benchmark](https://pubs.rsc.org/en/content/articlehtml/2018/sc/c7sc02664a) and consists of ~130k small, organic molecules with up to 9 heavy atoms. It also includes targets for various geometric, energetic, electronic and thermodynamic properties. Crucially, it also includes atom 3D coordinates, which makes it suitable for this talktorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the practical part, we will be working with a [version of QM9 that is already included in PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.QM9), as implementing the dataset from scratch would go beyond the scope of this talktorial. We will just inspect the data and briefly discuss how point clouds can be represented by several tensors. Then we will demonstrate how one could use plain GNNs to work with point clouds and why this approach would yield models that are not $\\text{E}(3)$ invariant/equivariant. Finally, you will learn how to implement, train and evaluate equivariant GNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "from itertools import chain, product\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional, Callable, Tuple, Dict, Sequence, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor, LongTensor\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.transforms import BaseTransform, Compose\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.nn.aggr import SumAggregation\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_scatter import scatter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of point clouds\n",
    "The following auxiliary function `plot_point_cloud_3d` will see heavy use later on for the visualization of model input and model outputs.\n",
    "Note that to visualize molecules rather than their tensor representations used for machine learning, it would be better to use e.g. `RDKit` or `NGLview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_perceived_brightness(rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Auxiliary function, useful for choosing label colors\n",
    "    with good visibility\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    return 0.1 * r + 0.8 * g + 0.1\n",
    "\n",
    "\n",
    "def plot_point_cloud_3d(\n",
    "    fig: mpl.figure.Figure,\n",
    "    ax_pos: int,\n",
    "    color: np.ndarray,\n",
    "    pos: np.ndarray,\n",
    "    cmap: str = \"plasma\",\n",
    "    point_size: float = 180.0,\n",
    "    label_axes: bool = False,\n",
    "    annotate_points: bool = True,\n",
    "    remove_axes_ticks: bool = True,\n",
    "    cbar_label: str = \"\",\n",
    ") -> mpl.axis.Axis:\n",
    "    \"\"\"Visualize colored 3D point clouds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig : mpl.figure.Figure\n",
    "        The figure for which a new axis object is added for plotting\n",
    "    ax_pos : int\n",
    "        Three-digit integer specifying axis layout and position\n",
    "        (see docs for `mpl.figure.Figure.add_subplot`)\n",
    "    color : np.ndarray\n",
    "        The point colors as a float array of shape `(N,)`\n",
    "    pos : np.ndarray\n",
    "        The point xyz-coordinates as an array of shape ``\n",
    "    cmap : str, optional\n",
    "        String identifier for a matplotlib colormap.\n",
    "        Is used to map the values in `color` to rgb colors.\n",
    "        , by default \"plasma\"\n",
    "    point_size : float, optional\n",
    "        The size of plotted points, by default 180.0\n",
    "    label_axes : bool, optional\n",
    "        whether to label x,y and z axes by default False\n",
    "    annotate_points : bool, optional\n",
    "        whether to label points with their index, by default True\n",
    "    cbar_label : str, optional\n",
    "        label for the colorbar, by default \"\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mpl.axis.Axis\n",
    "        The new axis object for the 3D point cloud plot.\n",
    "    \"\"\"\n",
    "    cmap = mpl.cm.get_cmap(cmap)\n",
    "    ax = fig.add_subplot(ax_pos, projection=\"3d\")\n",
    "    x, y, z = pos\n",
    "    if remove_axes_ticks:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_zticklabels([])\n",
    "    if label_axes:\n",
    "        ax.set_xlabel(\"$x$ coordinate\")\n",
    "        ax.set_ylabel(\"$y$ coordinate\")\n",
    "        ax.set_zlabel(\"$z$ coordinate\")\n",
    "    sc = ax.scatter(x, y, z, c=color, cmap=cmap, s=point_size)\n",
    "    plt.colorbar(sc, location=\"bottom\", shrink=0.6, anchor=(0.5, 2), label=cbar_label)\n",
    "    if annotate_points:\n",
    "        _colors = sc.cmap(color)\n",
    "        rgb = _colors[:, :3].transpose()\n",
    "        brightness = to_perceived_brightness(rgb)\n",
    "        for i, (xi, yi, zi, li) in enumerate(zip(x, y, z, brightness)):\n",
    "            ax.text(xi, yi, zi, str(i), None, color=[1 - li] * 3, ha=\"center\", va=\"center\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "# testing\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "for ax_pos in [221, 222, 223, 224]:\n",
    "    pos = np.random.rand(3, 5)\n",
    "    color = np.random.rand(5)\n",
    "    plot_point_cloud_3d(fig, ax_pos, color, pos)\n",
    "\n",
    "fig.suptitle(\"Random test point clouds\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_input(data: Data, fig: mpl.figure.Figure, ax_pos: int) -> mpl.axis.Axis:\n",
    "    \"\"\"\n",
    "    Plots 3D point cloud model input represented by a torch geometric\n",
    "    `Data` object. Use atomic numbers as colors.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Data\n",
    "        The 3D point cloud. Must have atomic numbers `z` and 2D coordinates `pos`\n",
    "        properties that are not `None`.\n",
    "    fig: mpl.figure.Figure\n",
    "        The maptlotlib figure to plot on.\n",
    "    ax_pos:\n",
    "        Three-digit integer specifying axis layout and position\n",
    "        (see docs for `mpl.figure.Figure.add_subplot`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mpl.axis.Axis\n",
    "        The newly created axis object.\n",
    "    \"\"\"\n",
    "    color, pos = data.z, data.pos\n",
    "    color = color.flatten().detach().numpy()\n",
    "    pos = pos.T.detach().numpy()\n",
    "    return plot_point_cloud_3d(fig, ax_pos, color, pos, cbar_label=\"Atomic number\")\n",
    "\n",
    "\n",
    "def plot_model_embedding(\n",
    "    data: Data, model: Callable[[Data], Tensor], fig: mpl.figure.Figure, ax_pos: int\n",
    ") -> mpl.axis.Axis:\n",
    "    \"\"\"\n",
    "    Same as `plot_model_input` but instead of node features as color,\n",
    "    first apply a GNN model to obtain colors from node embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Data\n",
    "        the model input. Must have 3D coordinates `pos`\n",
    "        an atomic number `z` properties that are not `None`.\n",
    "    model : Callable[[Data], Tensor]\n",
    "        the model must take Data objects as input and return node embeddings\n",
    "        as a Tensor output.\n",
    "    fig: mpl.figure.Figure\n",
    "        The maptlotlib figure to plot on.\n",
    "    ax_pos:\n",
    "        Three-digit integer specifying axis layout and position\n",
    "        (see docs for `mpl.figure.Figure.add_subplot`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mpl.axis.Axis\n",
    "        The newly created axis object.\n",
    "    \"\"\"\n",
    "    x = model(data)\n",
    "    pos = data.pos\n",
    "    color = x.flatten().detach().numpy()\n",
    "    pos = pos.T.detach().numpy()\n",
    "    return plot_point_cloud_3d(fig, ax_pos, color, pos, cbar_label=\"Atom embedding (1D)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and inspect the QM9 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "For the sake of this tutorial, we will restrict ourselves to small molecules with at most 8 heavy atoms. Due to our decision to ignore structural information and treat molecules as point clouds, where every atom interacts with every other atom, we also need to extend the torch geometric `Data` objects with additional adjacency information that represents a complete graph without self-loops.\n",
    "\n",
    "For performance reasons, both of these steps are performed *once* when pre-processing the raw data using the `pre_filter` and `pre_transform` keyword arguments of the dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_heavy_atoms(qm9_data: Data) -> int:\n",
    "    \"\"\"Count the number of heavy atoms in a torch geometric\n",
    "    Data object.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    qm9_data : Data\n",
    "        A pytorch geometric qm9 data object representing a small molecule\n",
    "         where atomic numbers are stored in a\n",
    "        tensor-valued attribute `qm9_data.z`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The number of heavy atoms in the molecule.\n",
    "    \"\"\"\n",
    "    # every atom with atomic number other than 1 is heavy\n",
    "    return (qm9_data.z != 1).sum()\n",
    "\n",
    "\n",
    "def complete_edge_index(n: int) -> LongTensor:\n",
    "    \"\"\"\n",
    "    Constructs a complete edge index.\n",
    "\n",
    "    NOTE: representing complete graphs\n",
    "    with sparse edge tensors is arguably a bad idea\n",
    "    due to performance reasons, but for this tutorial it'll do.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        the number of nodes in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    LongTensor\n",
    "        A PyTorch `edge_index` represents a complete graph with n nodes,\n",
    "        without self-loops. Shape (2, n).\n",
    "    \"\"\"\n",
    "    # filter removes self loops\n",
    "    edges = list(filter(lambda e: e[0] != e[1], product(range(n), range(n))))\n",
    "    return torch.tensor(edges, dtype=torch.long).T\n",
    "\n",
    "\n",
    "def add_complete_graph_edge_index(data: Data) -> Data:\n",
    "    \"\"\"\n",
    "    On top of any edge information already there,\n",
    "    add a second edge index that represents\n",
    "    the complete graph corresponding to a  given\n",
    "    torch geometric data object\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Data\n",
    "        The torch geometric data object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Data\n",
    "        The torch geometric `Data` object with a new\n",
    "        attribute `complete_edge_index` as described above.\n",
    "    \"\"\"\n",
    "    data.complete_edge_index = complete_edge_index(data.num_nodes)\n",
    "    return data\n",
    "\n",
    "\n",
    "#\n",
    "dataset = QM9(\n",
    "    DATA,\n",
    "    # Filter out molecules with more than 8 heavy atoms\n",
    "    pre_filter=lambda data: num_heavy_atoms(data) < 9,\n",
    "    # implement point cloud adjacency as a complete graph\n",
    "    pre_transform=add_complete_graph_edge_index,\n",
    ")\n",
    "\n",
    "print(f\"Num. examples in QM9 restricted to molecules with at most 8 heavy atoms: {len(dataset)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: executing the above cell for the first time first downloads and then processes the raw data, which **might take a while**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing the dataset we just created returns a single Pytorch Geometric `Data` object representing one molecular graph/point cloud. You can think of these objects as dictionaries with some extra utility methods already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "# This displays all named data attributes, and their shapes (in the case of tensors), or values (in the case of other data).\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For index 0 (name `gdb_1`) this should be the molecule CH4. We can check this by looking into the atomic numbers stored in the attributed named `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For molecules with `N` atoms and `M` (covalent) bonds, the data objects also contain named tensors of shape\n",
    "* `Data.x`: `(N, d_node)` node-level features (e.g. formal charge, membership to aromatic rings, chirality, ...), but we will ignore them here and just use atomic numbers.\n",
    "* `Data.y`: `(19,)` regression targets\n",
    "* `Data.edge_index`: `(2, M)` edges between atoms derived from covalent bonds, stored as source and target node index pairs.\n",
    "* `Data.edge_attr`: `(M, d_edge) contains bond features (e.g. bond type, ring-membership, ...)\n",
    "* `Data.pos`: `(N, 3)` most interesting to us, atom 3D coordinates.\n",
    "* `Data.complete_edge_index`: `(2, (N-1)^2)`: the complete graph edge index (without self-loops) we added earlier.\n",
    "\n",
    "The input to our (point cloud) model we will implement later can be visualized using just `Data.z` as color and `Data.pos` as scatter plot positions. Note: the alpha channel of colors is used to convey depth-information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.pos.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plot_model_input(data, fig, 111)\n",
    "_ = ax.set_title(\"CH$_4$ (Methane)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Atomic number distribution and point cloud size\n",
    "Now that our dataset is set up, and we have a basic understanding of how molecules are represented, we can try to visualize the properties of the entire dataset.\n",
    "Let us first look at the distribution of node-level features (atomic numbers) and the point cloud size (number of atoms) aggregated over the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_atoms, ax_graph_size) = plt.subplots(1, 2, figsize=(8, 5))\n",
    "\n",
    "# ax_atoms.hist(dataset.data.z[dataset.data.z != 1])\n",
    "ax_atoms.hist(dataset.data.z)\n",
    "ax_atoms.set_xlabel(\"Atomic number $z$\")\n",
    "ax_atoms.set_ylabel(\"Count\")\n",
    "num_nodes = [dataset[i].num_nodes for i in range(len(dataset))]\n",
    "ax_graph_size.hist(num_nodes)\n",
    "ax_graph_size.set_xlabel(\"Graph size (#nodes)\")\n",
    "fig.suptitle(\"Aggregated molecular point cloud properties\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that while fluorine atoms (number 9) show up in the data, they are heavily underrepresented (the bar at $z=9$ is barely visible), which is not a nice property that is likely since we shrunk the dataset. The number of atoms seems to be roughly normally distributed, which is nice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data split, distribution of regression target electronic spatial extent\n",
    "Next, we will implement data splitting, choose a regression target and visualize the split w.r.t. to this target. \n",
    "Out of the 19 regression targets included in QM9, we'll focus on *electronic spatial extent*, which, simply put, describes the volume of a molecule, so it should be a good fit for methods that use 3D information.\n",
    "Let us now start with implementing a *data module* that takes care of train/val/test splits and of indexing the correct target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9DataModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_ratio: float = 0.8,\n",
    "        val_ratio: float = 0.1,\n",
    "        test_ratio: float = 0.1,\n",
    "        target_idx: int = 5,\n",
    "        seed: float = 420,\n",
    "    ) -> None:\n",
    "        \"\"\"Encapsulates everything related to the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_ratio : float, optional\n",
    "            fraction of data used for training, by default 0.8\n",
    "        val_ratio : float, optional\n",
    "            fraction of data used for validation, by default 0.1\n",
    "        test_ratio : float, optional\n",
    "            fraction of data used for testing, by default 0.1\n",
    "        target_idx : int, optional\n",
    "            index of the target (see torch geometric docs), by default 5 (electronic spatial extent)\n",
    "            (https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html?highlight=qm9#torch_geometric.datasets.QM9)\n",
    "        seed : float, optional\n",
    "            random seed for data split, by default 420\n",
    "        \"\"\"\n",
    "        assert sum([train_ratio, val_ratio, test_ratio]) == 1\n",
    "        self.target_idx = target_idx\n",
    "        self.num_examples = len(self.dataset())\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.shuffled_index = rng.permutation(self.num_examples)\n",
    "        self.train_split = self.shuffled_index[: int(self.num_examples * train_ratio)]\n",
    "        self.val_split = self.shuffled_index[\n",
    "            int(self.num_examples * train_ratio) : int(\n",
    "                self.num_examples * (train_ratio + val_ratio)\n",
    "            )\n",
    "        ]\n",
    "        self.test_split = self.shuffled_index[\n",
    "            int(self.num_examples * (train_ratio + val_ratio)) : self.num_examples\n",
    "        ]\n",
    "\n",
    "    def dataset(self, transform=None) -> QM9:\n",
    "        dataset = QM9(\n",
    "            DATA,\n",
    "            pre_filter=lambda data: num_heavy_atoms(data) < 9,\n",
    "            pre_transform=add_complete_graph_edge_index,\n",
    "        )\n",
    "        dataset.data.y = dataset.data.y[:, self.target_idx].view(-1, 1)\n",
    "        return dataset\n",
    "\n",
    "    def loader(self, split, **loader_kwargs) -> DataLoader:\n",
    "        dataset = self.dataset()[split]\n",
    "        return DataLoader(dataset, **loader_kwargs)\n",
    "\n",
    "    def train_loader(self, **loader_kwargs) -> DataLoader:\n",
    "        return self.loader(self.train_split, shuffle=True, **loader_kwargs)\n",
    "\n",
    "    def val_loader(self, **loader_kwargs) -> DataLoader:\n",
    "        return self.loader(self.val_split, shuffle=False, **loader_kwargs)\n",
    "\n",
    "    def test_loader(self, **loader_kwargs) -> DataLoader:\n",
    "        return self.loader(self.test_split, shuffle=False, **loader_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily plot the target across the data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = QM9DataModule()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6), sharey=True)\n",
    "target = data_module.dataset().data.y.flatten().numpy()\n",
    "ax1.boxplot(\n",
    "    [\n",
    "        target[data_module.train_split],\n",
    "        target[data_module.val_split],\n",
    "        target[data_module.test_split],\n",
    "    ]\n",
    ")\n",
    "ax1.set_xticklabels([\"Train\", \"Val\", \"Test\"])\n",
    "ax1.set_ylabel(\"Electronic spatial extent $\\langle R^2 \\\\rangle$\")\n",
    "\n",
    "for label, split in {\n",
    "    \"Train\": data_module.train_split,\n",
    "    \"Val\": data_module.val_split,\n",
    "    \"Test\": data_module.test_split,\n",
    "}.items():\n",
    "    ax2.scatter(split, target[split], label=label, s=1)\n",
    "\n",
    "ax2.set_xlabel(\"Example index\")\n",
    "ax2.legend()\n",
    "fig.suptitle(\"Random data split - target distribution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to observe that random splits are typically very homogenous, which means measuring generalization capabilities with them can yield deceivingly good results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plain \"naive Euclidean\" GNN\n",
    "A naive way to incorporate 3D coordinates into a GNN for molecular graphs would be to interpret them as atom-level features that are simply combined with the other features.\n",
    "It is easy to implement a simple baseline model which does exactly this (see **Talktorial 034**).\n",
    "For its message-passing topology, our implementation uses the edges induced by bonds between atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveEuclideanGNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int,\n",
    "        num_layers: int,\n",
    "        num_spatial_dims: int,\n",
    "        final_embedding_size: Optional[int] = None,\n",
    "        act: nn.Module = nn.ReLU(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # NOTE nn.Embedding acts like a lookup table.\n",
    "        # Here we use it to store each atomic number in [0,100]\n",
    "        # a learnable, fixed-size vector representation\n",
    "        self.f_initial_embed = nn.Embedding(100, hidden_channels)\n",
    "        self.f_pos_embed = nn.Linear(num_spatial_dims, hidden_channels)\n",
    "        self.f_combine = nn.Sequential(nn.Linear(2 * hidden_channels, hidden_channels), act)\n",
    "\n",
    "        if final_embedding_size is None:\n",
    "            final_embedding_size = hidden_channels\n",
    "\n",
    "        # Graph isomorphism network as main GNN\n",
    "        # (see Talktorial 034)\n",
    "        # takes care of message passing and\n",
    "        # Learning node-level embeddings\n",
    "        self.gnn = geom_nn.models.GIN(\n",
    "            in_channels=hidden_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=final_embedding_size,\n",
    "            num_layers=num_layers,\n",
    "            act=act,\n",
    "        )\n",
    "\n",
    "        # modules required for aggregating node embeddings\n",
    "        # into graph embeddings and making graph-level predictions\n",
    "        self.aggregation = geom_nn.aggr.SumAggregation()\n",
    "        self.f_predict = nn.Sequential(\n",
    "            nn.Linear(final_embedding_size, final_embedding_size),\n",
    "            act,\n",
    "            nn.Linear(final_embedding_size, 1),\n",
    "        )\n",
    "\n",
    "    def encode(self, data: Data) -> Tensor:\n",
    "        # initial atomic number embedding and embedding od positional information\n",
    "        atom_embedding = self.f_initial_embed(data.z)\n",
    "        pos_embedding = self.f_pos_embed(data.pos)\n",
    "\n",
    "        # treat both as plain node-level features and combine into initial node-level\n",
    "        # embedddings\n",
    "        initial_node_embed = self.f_combine(torch.cat((atom_embedding, pos_embedding), dim=-1))\n",
    "\n",
    "        # message passing\n",
    "        # NOTE in contrast to the EGNN implemented later, this model does use bond information\n",
    "        # i.e., data.egde_index stems from the bond adjacency matrix\n",
    "        node_embed = self.gnn(initial_node_embed, data.edge_index)\n",
    "        return node_embed\n",
    "\n",
    "    def forward(self, data: Data) -> Tensor:\n",
    "        node_embed = self.encode(data)\n",
    "        aggr = self.aggregation(node_embed, data.batch)\n",
    "        return self.f_predict(aggr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo: Plain GNNs are not $\\text{E(3)}$-invariant\n",
    "However, this approach is problematic because the corresponding atom embeddings of a regular GNN (from which we would also derive our final predictions) will not be $\\text{E}(3)$-invariant. This can be demonstrated easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use rotations along z-axis as demo e(3) transformation\n",
    "def rotation_matrix_z(theta: float) -> Tensor:\n",
    "    \"\"\"Generates a rotation matrix and returns\n",
    "    a corresponing tensor. The rotation is about the $z$-axis.\n",
    "    (https://en.wikipedia.org/wiki/Rotation_matrix)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta : float\n",
    "        the angle of rotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor\n",
    "        the rotation matrix as float tensor.\n",
    "    \"\"\"\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            [math.cos(theta), -math.sin(theta), 0],\n",
    "            [math.sin(theta), math.cos(theta), 0],\n",
    "            [0, 0, 1],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE*: you may need to run the cell below multiple times to find a model initialization for which non-invariance can easily be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data points from qm9\n",
    "sample_data = dataset[800].clone()\n",
    "\n",
    "# apply an E(3) transformation\n",
    "rotated_sample_data = sample_data.clone()\n",
    "rotated_sample_data.pos = rotated_sample_data.pos @ rotation_matrix_z(45)\n",
    "\n",
    "# initialize a model with 2 hidden layers, 32 hidden channels,\n",
    "# that outputs 1-dimensional node embeddings\n",
    "model = NaiveEuclideanGNN(\n",
    "    hidden_channels=32,\n",
    "    num_layers=2,\n",
    "    num_spatial_dims=3,\n",
    "    final_embedding_size=1,\n",
    ")\n",
    "\n",
    "# make a plot that demonstrates non-equivariance\n",
    "# fig, axes = plt.subplots(2, 2, figsize=(8,8), sharex=True, sharey=True)\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax1 = plot_model_input(sample_data, fig, 221)\n",
    "ax1.set_title(\"Sample input $(X, Z)$\")\n",
    "\n",
    "ax2 = plot_model_input(rotated_sample_data, fig, 222)\n",
    "ax2.set_title(\"Rotated input $(X, g(Z))$\")\n",
    "\n",
    "ax3 = plot_model_embedding(sample_data, model.encode, fig, 223)\n",
    "ax3.set_title(\"Model output for $(X, Z)$\")\n",
    "\n",
    "ax4 = plot_model_embedding(rotated_sample_data, model.encode, fig, 224)\n",
    "ax4.set_title(\"Model output for $(X, g(Z))$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executing the above cells a few times, we can observe that rotating the molecule may *significantly* alter the atom embeddings obtained from the plain GNN model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EGNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement an $\\text{E}(n)$-invariant GNN based on the principles outlined in the theory section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivariantMPLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        act: nn.Module,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.act = act\n",
    "        self.residual_proj = nn.Linear(in_channels, hidden_channels, bias=False)\n",
    "\n",
    "        # Messages will consist of two (source and target) node embeddings and a scalar distance\n",
    "        message_input_size = 2 * in_channels + 1\n",
    "\n",
    "        # equation (3) \"phi_l\" NN\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(message_input_size, hidden_channels),\n",
    "            act,\n",
    "        )\n",
    "        # equation (4) \"psi_l\" NN\n",
    "        self.node_update_mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels + hidden_channels, hidden_channels),\n",
    "            act,\n",
    "        )\n",
    "\n",
    "    def node_message_function(\n",
    "        self,\n",
    "        source_node_embed: Tensor,  # h_i\n",
    "        target_node_embed: Tensor,  # h_j\n",
    "        node_dist: Tensor,  # d_ij\n",
    "    ) -> Tensor:\n",
    "        # implements equation (3)\n",
    "        message_repr = torch.cat((source_node_embed, target_node_embed, node_dist), dim=-1)\n",
    "        return self.message_mlp(message_repr)\n",
    "\n",
    "    def compute_distances(self, node_pos: Tensor, edge_index: LongTensor) -> Tensor:\n",
    "        row, col = edge_index\n",
    "        xi, xj = node_pos[row], node_pos[col]\n",
    "        # relative squared distance\n",
    "        # implements equation (2) ||X_i - X_j||^2\n",
    "        rsdist = (xi - xj).pow(2).sum(1, keepdim=True)\n",
    "        return rsdist\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        node_embed: Tensor,\n",
    "        node_pos: Tensor,\n",
    "        edge_index: Tensor,\n",
    "    ) -> Tensor:\n",
    "        row, col = edge_index\n",
    "        dist = self.compute_distances(node_pos, edge_index)\n",
    "\n",
    "        # compute messages \"m_ij\" from  equation (3)\n",
    "        node_messages = self.node_message_function(node_embed[row], node_embed[col], dist)\n",
    "\n",
    "        # message sum aggregation in equation (4)\n",
    "        aggr_node_messages = scatter(node_messages, col, dim=0, reduce=\"sum\")\n",
    "\n",
    "        # compute new node embeddings \"h_i^{l+1}\"\n",
    "        # (implements rest of equation (4))\n",
    "        new_node_embed = self.residual_proj(node_embed) + self.node_update_mlp(\n",
    "            torch.cat((node_embed, aggr_node_messages), dim=-1)\n",
    "        )\n",
    "\n",
    "        return new_node_embed\n",
    "\n",
    "\n",
    "class EquivariantGNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int,\n",
    "        final_embedding_size: Optional[int] = None,\n",
    "        target_size: int = 1,\n",
    "        num_mp_layers: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if final_embedding_size is None:\n",
    "            final_embedding_size = hidden_channels\n",
    "\n",
    "        # non-linear activation func.\n",
    "        # usually configurable, here we just use Relu for simplicity\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # equation (1) \"psi_0\"\n",
    "        self.f_initial_embed = nn.Embedding(100, hidden_channels)\n",
    "\n",
    "        # create stack of message passing layers\n",
    "        self.message_passing_layers = nn.ModuleList()\n",
    "        channels = [hidden_channels] * (num_mp_layers) + [final_embedding_size]\n",
    "        for d_in, d_out in zip(channels[:-1], channels[1:]):\n",
    "            layer = EquivariantMPLayer(d_in, d_out, self.act)\n",
    "            self.message_passing_layers.append(layer)\n",
    "\n",
    "        # modules required for readout of a graph-level\n",
    "        # representation and graph-level property prediction\n",
    "        self.aggregation = SumAggregation()\n",
    "        self.f_predict = nn.Sequential(\n",
    "            nn.Linear(final_embedding_size, final_embedding_size),\n",
    "            self.act,\n",
    "            nn.Linear(final_embedding_size, target_size),\n",
    "        )\n",
    "\n",
    "    def encode(self, data: Data) -> Tensor:\n",
    "        # theory, equation (1)\n",
    "        node_embed = self.f_initial_embed(data.z)\n",
    "        # message passing\n",
    "        # theory, equation (3-4)\n",
    "        for mp_layer in self.message_passing_layers:\n",
    "            # NOTE here we use the complete edge index defined by the transform earlier on\n",
    "            # to implement the sum over $j \\neq i$ in equation (4)\n",
    "            node_embed = mp_layer(node_embed, data.pos, data.complete_edge_index)\n",
    "        return node_embed\n",
    "\n",
    "    def _predict(self, node_embed, batch_index) -> Tensor:\n",
    "        aggr = self.aggregation(node_embed, batch_index)\n",
    "        return self.f_predict(aggr)\n",
    "\n",
    "    def forward(self, data: Data) -> Tensor:\n",
    "        node_embed = self.encode(data)\n",
    "        pred = self._predict(node_embed, data.batch)\n",
    "        return pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo: Our EGNN is $E(3)$-invariant\n",
    "We can collect evidence that this model is indeed $\\text{E}(n)$-invariant by repeating the experiment we conducted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EquivariantGNN(hidden_channels=32, final_embedding_size=1, num_mp_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data points from qm9\n",
    "sample_data = dataset[800].clone()\n",
    "\n",
    "# apply E(3) transformation\n",
    "rotated_sample_data = sample_data.clone()\n",
    "rotated_sample_data.pos = rotated_sample_data.pos @ rotation_matrix_z(120)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "ax1 = plot_model_input(sample_data, fig, 221)\n",
    "ax1.set_title(\"Sample input $(X, Z)$\")\n",
    "\n",
    "ax2 = plot_model_input(rotated_sample_data, fig, 222)\n",
    "ax2.set_title(\"Rotated input $(X, g(Z))$\")\n",
    "\n",
    "ax3 = plot_model_embedding(sample_data, model.encode, fig, 223)\n",
    "ax3.set_title(\"Model output for $(X, Z)$\")\n",
    "\n",
    "ax4 = plot_model_embedding(rotated_sample_data, model.encode, fig, 224)\n",
    "ax4.set_title(\"Model output for $(X, g(Z))$\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can execute the above cells as often as you like, with whatever input you choose, the atom embeddings will always be unaffected by the rotation applied to the model input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation\n",
    "Now that we have set up our data and implemented two different models for point clouds, we can start implementing a training and evaluation pipeline.\n",
    "\n",
    "We will follow the ubiquitous ML principle of also monitoring a validation loss in addition to the training loss. The validation loss acts as an estimate for how well the model generalizes and can be used for selecting a final model to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using mean absolute error\n",
    "# as a metric for validation and testing\n",
    "def total_absolute_error(pred: Tensor, target: Tensor, batch_dim: int = 0) -> Tensor:\n",
    "    \"\"\"Total absolute error, i.e. sums over batch dimension.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : Tensor\n",
    "        batch of model predictions\n",
    "    target : Tensor\n",
    "        batch of ground truth / target values\n",
    "    batch_dim : int, optional\n",
    "        dimension that indexes batch elements, by default 0\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor\n",
    "        total absolute error\n",
    "    \"\"\"\n",
    "    return (pred - target).abs().sum(batch_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: Callable[[Tensor, Tensor], Tensor],\n",
    "    pbar: Optional[Any] = None,\n",
    "    optim: Optional[torch.optim.Optimizer] = None,\n",
    "):\n",
    "    \"\"\"Run a single epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        the NN used for regression\n",
    "    loader : DataLoader\n",
    "        an iterable over data batches\n",
    "    criterion : Callable[[Tensor, Tensor], Tensor]\n",
    "        a criterion (loss) that is optimized\n",
    "    pbar : Optional[Any], optional\n",
    "        a tqdm progress bar, by default None\n",
    "    optim : Optional[torch.optim.Optimizer], optional\n",
    "        a optimizer that is optimizing the criterion, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    def step(\n",
    "        data_batch: Data,\n",
    "    ) -> Tuple[float, float]:\n",
    "        \"\"\"Perform a single train/val step on a data batch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_batch : Data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[float, float]\n",
    "            Loss (mean squared error) and validation critierion (absolute error).\n",
    "        \"\"\"\n",
    "        pred = model.forward(data_batch)\n",
    "        target = data_batch.y\n",
    "        loss = criterion(pred, target)\n",
    "        if optim is not None:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        return loss.detach().item(), total_absolute_error(pred.detach(), target.detach())\n",
    "\n",
    "    if optim is not None:\n",
    "        model.train()\n",
    "        # This enables pytorch autodiff s.t. we can compute gradients\n",
    "        model.requires_grad_(True)\n",
    "    else:\n",
    "        model.eval()\n",
    "        # disable autodiff: when evaluating we do not need to track gradients\n",
    "        model.requires_grad_(False)\n",
    "\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for data in loader:\n",
    "        loss, mae = step(data)\n",
    "        total_loss += loss * data.num_graphs\n",
    "        total_mae += mae\n",
    "        if pbar is not None:\n",
    "            pbar.update(1)\n",
    "\n",
    "    return total_loss / len(loader.dataset), total_mae / len(loader.dataset)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    data_module: QM9DataModule,\n",
    "    model: nn.Module,\n",
    "    num_epochs: int = 30,\n",
    "    lr: float = 3e-4,\n",
    "    batch_size: int = 32,\n",
    "    weight_decay: float = 1e-8,\n",
    "    best_model_path: Path = DATA.joinpath(\"trained_model.pth\"),\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Takes data and model as input and runs training, collecting additional validation metrics\n",
    "    while doing so.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_module : QM9DataModule\n",
    "        a data module as defined earlier\n",
    "    model : nn.Module\n",
    "        a gnn model\n",
    "    num_epochs : int, optional\n",
    "        number of epochs to train for, by default 30\n",
    "    lr : float, optional\n",
    "        \"learning rate\": optimizer SGD step size, by default 3e-4\n",
    "    batch_size : int, optional\n",
    "        number of examples used for one training step, by default 32\n",
    "    weight_decay : float, optional\n",
    "        L2 regularization parameter, by default 1e-8\n",
    "    best_model_path : Path, optional\n",
    "        path where the model weights with lowest val. error should be stored\n",
    "        , by default DATA.joinpath(\"trained_model.pth\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        a training result, ie statistics and info about the model\n",
    "    \"\"\"\n",
    "    # create data loaders\n",
    "    train_loader = data_module.train_loader(batch_size=batch_size)\n",
    "    val_loader = data_module.val_loader(batch_size=batch_size)\n",
    "\n",
    "    # setup optimizer and loss\n",
    "    optim = torch.optim.Adam(model.parameters(), lr, weight_decay=1e-8)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # keep track of the epoch with the best validation mae\n",
    "    # st we can save the \"best\" model weights\n",
    "    best_val_mae = float(\"inf\")\n",
    "\n",
    "    # Statistics that will be plotted later on\n",
    "    # and model info\n",
    "    result = {\n",
    "        \"model\": model,\n",
    "        \"path_to_best_model\": best_model_path,\n",
    "        \"train_loss\": np.full(num_epochs, float(\"nan\")),\n",
    "        \"val_loss\": np.full(num_epochs, float(\"nan\")),\n",
    "        \"train_mae\": np.full(num_epochs, float(\"nan\")),\n",
    "        \"val_mae\": np.full(num_epochs, float(\"nan\")),\n",
    "    }\n",
    "\n",
    "    # Auxiliary functions for updating and reporting\n",
    "    # Training progress statistics\n",
    "    def update_statistics(i_epoch: int, **kwargs: float):\n",
    "        for key, value in kwargs.items():\n",
    "            result[key][i_epoch] = value\n",
    "\n",
    "    def desc(i_epoch: int) -> str:\n",
    "        return \" | \".join(\n",
    "            [f\"Epoch {i_epoch + 1:3d} / {num_epochs}\"]\n",
    "            + [\n",
    "                f\"{key}: {value[i_epoch]:8.2f}\"\n",
    "                for key, value in result.items()\n",
    "                if isinstance(value, np.ndarray)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # main training loop\n",
    "    for i_epoch in range(0, num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_loader) + len(val_loader))\n",
    "        try:\n",
    "            # tqdm for reporting progress\n",
    "            progress_bar.set_description(desc(i_epoch))\n",
    "\n",
    "            # training epoch\n",
    "            train_loss, train_mae = run_epoch(model, train_loader, loss_fn, progress_bar, optim)\n",
    "            # validation epoch\n",
    "            val_loss, val_mae = run_epoch(model, val_loader, loss_fn, progress_bar)\n",
    "\n",
    "            update_statistics(\n",
    "                i_epoch,\n",
    "                train_loss=train_loss,\n",
    "                val_loss=val_loss,\n",
    "                train_mae=train_mae,\n",
    "                val_mae=val_mae,\n",
    "            )\n",
    "\n",
    "            progress_bar.set_description(desc(i_epoch))\n",
    "\n",
    "            if val_mae < best_val_mae:\n",
    "                best_val_mae = val_mae\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "        finally:\n",
    "            progress_bar.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model(model: nn.Module, data_module: QM9DataModule) -> Tuple[float, Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Test a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        a trained model\n",
    "    data_module : QM9DataModule\n",
    "        a data module as defined earlier\n",
    "        from which we'll get the test data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _Tuple[float, Tensor, Tensor]\n",
    "        Test MAE, and model predictions & targets for further processing\n",
    "    \"\"\"\n",
    "    test_mae = 0\n",
    "    preds, targets = [], []\n",
    "    loader = data_module.test_loader()\n",
    "    for data in loader:\n",
    "        pred = model(data)\n",
    "        target = data.y\n",
    "        preds.append(pred)\n",
    "        targets.append(target)\n",
    "        test_mae += total_absolute_error(pred, target).item()\n",
    "\n",
    "    test_mae = test_mae / len(data_module.test_split)\n",
    "\n",
    "    return test_mae, torch.cat(preds, dim=0), torch.cat(targets, dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EquivariantGNN(hidden_channels=64, num_mp_layers=2)\n",
    "\n",
    "egnn_train_result = train_model(\n",
    "    data_module,\n",
    "    model,\n",
    "    num_epochs=25,\n",
    "    lr=2e-4,\n",
    "    batch_size=32,\n",
    "    weight_decay=1e-8,\n",
    "    best_model_path=DATA.joinpath(\"trained_egnn.pth\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the plain GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_baseline = NaiveEuclideanGNN(64, 4, 3)\n",
    "\n",
    "gcn_train_result = train_model(\n",
    "    data_module,\n",
    "    gcn_baseline,\n",
    "    num_epochs=100,\n",
    "    lr=3e-4,\n",
    "    batch_size=32,\n",
    "    best_model_path=DATA.joinpath(\"trained_gnn.pth\"),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparative evaluation\n",
    "\n",
    "Let us now compare the trained EGNN and GNN baseline model. First note that in terms of capacity (measured by the number of trainable parameters) the models are very similar. But be aware that the comparison is still not completely fair, because\n",
    "* the EGNN is a *message-passing* neural network while the baseline GNN is a type of *graph convolutional* neural network\n",
    "* the EGNN is run on complete graphs, whereas the baseline GNN uses the bond adjacency info, which could also be a disadvantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_num_params = sum(p.numel() for p in gcn_train_result[\"model\"].parameters())\n",
    "egnn_num_params = sum(p.numel() for p in egnn_train_result[\"model\"].parameters())\n",
    "\n",
    "for key, value in {\"GCN\": gcn_num_params, \"EGNN\": egnn_num_params}.items():\n",
    "    print(f\"{key} has {value} parameters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss and validation MAE for each epoch, we can observe that the EGNN training progresses *much* faster and yields *much* better results,\n",
    "even though it is trained for a smaller number of epochs (note that loss and MAE are in log-scale).\n",
    "\n",
    "Surprisingly the validation loss/MAE for the EGNN is sometimes *lower* than the train loss/MAE. This might be explained by the fact that the data split is *very* homogenous, and the validation data contains fewer outliers than the train data (see box plots from the section on distribution of regression target across splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (loss_ax, mae_ax) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "loss_ax.set_title(\"Loss (MSE)\")\n",
    "mae_ax.set_title(\"MAE\")\n",
    "loss_ax.set_xlabel(\"Epoch\")\n",
    "mae_ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "for metric in [\"train_loss\", \"val_loss\", \"train_mae\", \"val_mae\"]:\n",
    "    split = metric.split(\"_\")[0]\n",
    "    ax = loss_ax if \"loss\" in metric else mae_ax\n",
    "\n",
    "    ax.plot(egnn_train_result[metric], label=f\"EGNN {split}\")\n",
    "    ax.plot(gcn_train_result[metric], label=f\"GNN {split}\")\n",
    "\n",
    "mae_ax.legend()\n",
    "mae_ax.set_yscale(\"log\")\n",
    "loss_ax.set_yscale(\"log\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performance improvement can also be observed in the held-out test data. For testing, we select the best model as the model that had the lowest validation MAE each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = gcn_train_result[\"model\"]\n",
    "gcn_model.load_state_dict(torch.load(gcn_train_result[\"path_to_best_model\"]))\n",
    "gcn_test_mae, gcn_preds, gcn_targets = test_model(gcn_model, data_module)\n",
    "\n",
    "egnn_model = egnn_train_result[\"model\"]\n",
    "egnn_model.load_state_dict(torch.load(egnn_train_result[\"path_to_best_model\"]))\n",
    "egnn_test_mae, egnn_preds, egnn_targets = test_model(egnn_model, data_module)\n",
    "\n",
    "print(f\"EGNN test MAE: {egnn_test_mae}\")\n",
    "print(f\"GNN test MAE: {gcn_test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(gcn_targets, gcn_targets, \"--\", color=\"grey\")\n",
    "ax.scatter(gcn_targets, gcn_preds, s=1, label=\"GNN\")\n",
    "ax.scatter(egnn_targets, egnn_preds, s=1, label=\"EGNN\")\n",
    "ax.set_ylabel(\"Model prediction\")\n",
    "ax.set_xlabel(\"Ground truth $\\langle R^2 \\\\rangle$\")\n",
    "ax.set_title(\"Test performance\")\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These findings support our initial hypothesis that $\\text{E}(3)$-invariant models lead to faster learning and improved generalization performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### Summary\n",
    "You have now seen, theoretically and practically, why we need $(S)E(3)$ to work with point cloud representations of molecules and how to implement, train and evaluate them. The dataset used here is not directly relevant to CADD, but the practical importance of $(S)E(3)$ equi-/invariance definitely carries over to more relevant applications such as protein ligand docking. Recent work on molecular representation learning also suggests that 3D point clouds are favored for a broad range of property prediction tasks more relevant to CADD such as toxicity prediction.\n",
    "\n",
    "### Caveats of our approach\n",
    "At this point, we should also go over some final caveats with the EGNN presented here and our approach in general:\n",
    "\n",
    "1. Our model assumes that every atom interacts with every other atom, i.e. the neighborhood of node $i$, $N(i) = \\{j \\neq i\\}$ is complete. This approach has quadratic complexity meaning its more computationally expensive (go back to the model training and compare how long one epoch takes compared to the plain GNN) and thus might not be scalable to larger molecules. In this case we could restrict interactions by instead using \n",
    "   * $k$-nearest neighborhoods, i.e. $|N(i)| = k$ contains the $k$ nodes with the smallest euclidean distance to $i$,\n",
    "   * or spherical neighborhoods with a fixed radius $\\delta$ instead, i.e. $N(i) = \\{j \\mid ||X_i - X_j||^2 \\leq \\delta\\}$\n",
    "3. Our EGNN model is $E(3)$-invariant. Note that some molecular properties are *sensitive* to reflection, In such settings, $SE(3)$-invariance should be the preferred model property (see **Talktorial 033**).\n",
    "4. Random data splits are considered bad practice for measuring the capability of a molecular machine learning model to generalize to unseen data (see [this paper](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0391-2) which analyzes and discusses this issue in-depth for QM9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. In addition to 3D coordinates, what is strictly required for inference of covalent bonds between atoms?\n",
    "2. What is the difference between equivariance and invariance?\n",
    "3. True or false? $SE(3)$ contains transformations which are not included in $E(3)$.\n",
    "4. True or false? The atom embeddings $h$ computed by iterating the following message passing scheme for a fixed number of steps are $E(3)$-invariant\n",
    "\\begin{align*}\n",
    "    m_{ij}^{l} &= \\phi_{l}(h_i^l, h_j^l, X_i - X_j)  \\\\\n",
    "    h_{i}^{l+1} &= \\psi_l(h_{i}^l, \\sum_{j \\neq i} m_{ij}^l)\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Useful checks at the end</b>: \n",
    "    \n",
    "<ul>\n",
    "<li>Clear output and rerun your complete notebook. Does it finish without errors?</li>\n",
    "<li>Check if your talktorial's runtime is as excepted. If not, try to find out which step(s) take unexpectedly long.</li>\n",
    "<li>Flag code cells with <code># NBVAL_CHECK_OUTPUT</code> that have deterministic output and should be tested within our Continuous Integration (CI) framework.</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a9b266ef77d2c7845c34a2fd631702a12f40ca31c61a4ac43e85fda7905a5a1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
